#summary Things remaining to do
#labels roadmap

*Preparations for multicore*

  *  The multi-threaded mapping needs further work to ensure that maps whose consistency scores fall too far behind the best performing map are replaced, in a similar manner to a genetic algorithm.  The key factor here is to find efficient online methods for doing this, which do not impede real time performance.

  *  If multiple stereo cameras are attached to the robot each stereo correspondence algorithm should run in its own thread


*Gathering more data*

  *  More stereo image and ground truth data sets would be helpful.  This would help to improve confidence that the system is going to work within a wide variety of situations.  If a mobile robot testing platform becomes available these data sets can be gathered in a far less labour intensive way.


*Integration testing*

At some point integration testing needs to be carried out on a mobile robot platform.  The essentials here are that the robot has an onboard PC (or laptop) and reasonably accurate wheel encoder feedback for dead reckoning.  Either the position or velocity based motion model needs to accept input from the robot's odometry.

  *  Characterisation of odometry errors on typical surfaces (carpets, wooden floors, etc).  Run the robot multiple times on both straight line and turning paths over a couple of metres and record the position estimated by dead reckoning and the robot's actual final position.  The motion model parameters governing the rate of increase in position uncertainty can then be estimated based upon these results.

  *  Optimisation of mapping performance.  Various parameters affect the mapping performance, such as the number of particles representing position uncertainty.  More particles can increase the robot's level of certainty about its position but also slows the update time.  An optimal compromise needs to be found between speed of computation and the accuracy of pose estimation at any given time step.


*Monte carlo localisation*

Creating new grid maps is one thing, but for full autonomy the robot also needs to be able to identify that it is located somewhere within a previously created map - solving the _kidnapped robot problem_.  An MCL algorithm needs to be implemented, running in its own thread.  Fortunately this should be quite straightforward because almost all of the necessary code can be reused from the existing SLAM mapping.


*Occupancy grid visualisation*

Some minor coding needs to be done to ensure that colours are properly represented when exporting the grid in a format which [http://home.fnal.gov/~gnedin/IFRIT/ IFrIT] can read.