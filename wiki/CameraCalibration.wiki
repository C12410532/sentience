#summary Calibrating methods for stereo cameras
#labels calibration,cameralens

Camera images normally contain some amount of spherical distortion, sometimes known as the _goldfish bowl effect_.  Linear features such as chair legs or door frames may appear to be warped, especially at the periphery of the image.  The job of camera calibration is to discover the nature of this distortion so that the resulting image may subsequently be undistorted or [ImageRectification rectified].

Various methods of calibration exist.  The simplest method assumes a perfectly symmetrical lens around the [CentreOfDistortion centre of distortion], and uses a polynomial equation to represent how light rays are bent radially around this by the curvature of the lens.

The typical method of calibration involves having the camera observe a test pattern, which can consist of spots, lines or squares (or indeed any easily identifiable repeating pattern).  Since the real geometry of the pattern is known the lens distortion can be calculated, then used to rectify the image back into a flat geometry.

=== Stages of Calibration ===

The images below show the stages involved in the calibration process.

[http://sentience.googlegroups.com/web/calibration_steps.jpg]

1.  *Edge detection*  Edges are detected within the entire image, or within some _region of interest_ which contains the calibration pattern.  Edges are local points of high contrast, and a competitive _non-maximal supression_ is used to show only the strongest features.  In order to make edge detection more robust multiple images taken over a period of time are integrated together.  This helps to average out much of the noise normally present within webcam images.

2.  *Line detection*  Once edges have been detected horizontally and vertically oriented lines can be fitted to them.  Some extra local fitting is done to ensure that the lines closely match those within the original image.

3.  *Corner detection*  When lines have been found the intersections between lines may be used to discover corner features.

4.  *Centre spot detection*  We also need to know the centre position of the calibration pattern, because this is at a known distance from the camera.  The centre of the pattern is indicated by a small spot, which is offset north west, north east, south west or south east from the centre of pattern.  The centre spot is easily located by searching for the maximal _off-centre_ response within the image which has not been previously identified as a corner feature.  The corner feature which corresponds to the centre of the pattern is marked with a small white square.

5.  *Forward feature projection*  Knowning the position of the centre of the calibration pattern, its distance from the camera, the height of the camera above the ground, field of vision and the spacing of the pattern we can then calculate where corner features _ought to appear_ within the image if it were perfectly rectified.  This is a kind of top-down expectation projected into image coordinates.

6.  *Polynomial curve fit*  We can plot the radial positions (distance from the centre of the image) for the observed corners and the forward projected corners on a 2D graph and use classical polynomial curve fitting in order to discover the shape of the image distortion caused by the camera lens.  The fitting procedure may be carried out using an origin within some small radius of the centre of the image, and the solution with the smallest _root mean squared_ error then gives us a position for the _centre of the distortion_.

[http://sentience.googlegroups.com/web/calibration_polynomial.jpg]

7.  *Shake and bake*  Once a good curve fit has been discovered a small amount of random noise is added and a secondary function is used to evaluate the quality of fit to the image, by comparing the rectified corner feature positions to the forward projected corners.  This annealing process allows the curve to be fine tuned to get the closest possible match.

The stereo images below show the difference between the rectified corner positions and the ideal forward projected positions, with white lines indicating the error magnitude.

[http://sentience.googlegroups.com/web/calibration_errors.jpg]

8.  *Rectification*  The centre of distorion and polynomial curve may be used to rectify images from the camera.


The assumption that the lens distortion is radially symmetric is of course not always true, especially on low cost webcams where the quality of manufacture may not be especially high.

=== Users guide ===

[http://sentience.googlegroups.com/web/fishfood.jpg]

Sentience contains an automatic monocular or stereo camera calibration system, called FishFood.  The procedure requires a calibration pattern, but I have tried to keep the system as simple as possible, such that it could be carried out _in the field_ by a non-expert using only easily available materials.

Ingredients required:

  *  [HowToMakeAStereoCamera Stereo camera]
  *  Large piece of cardboard
  *  Black marker pen
  *  Tape measure
  *  Straight object to use as a drawing guide, such as a ruler or piece of wood

Instructions:

1.  Draw a grid pattern on the cardboard using the pen and some straight object as a guide.  Cardboard is a good material to use, since it is non-reflective and easy to draw on.  You can choose anything you like as the spacing between lines (provided that it's regular).  I've found that 50 millimetres (5cm) seems to be a good spacing value.  Also, draw a small spot about 1.5cm in diameter to the north west of the centre of the pattern.

2.  Lay the calibration pattern down on the floor and have the stereo camera look down towards the centre of the pattern.  Ensure that the centre of the two cameras is aligned with the centre of the pattern.  The cameras would typically be mounted on a pan and tilt mechanism on the head of a robot, but in this case I'm just using the back of a chair as a substitute for a mobile robot.

[http://sentience.googlegroups.com/web/calibration_pattern.jpg]

3.  Measure the distance along the ground from the stereo camera to the centre of the calibration pattern.  Also, measure the height of the cameras above the floor.  To be as accurate as possible you should be measuring distances from the lenses of the cameras.

4.  Run the calibration program and enter the measurement values, pattern spacing, field of vision and stereo camera baseline distance, then from *video* on the menu bar select *start camera*.  The program has two modes of operation: _alignment mode_ and _calibration mode_, toggled by the button at the top left of the screen.  When video streaming initially commences you will be in alignment mode.  When the cameras are running use the large white crosshairs to align the cameras with the pattern, like this:

[http://sentience.googlegroups.com/web/calibration_roi.jpg]

*Additional note:  The Creative Webcam NX Ultra cameras used in this example already appear to be pre-rectified either in hardware or as part of their software drivers.  This seems to be the exception rather than the norm, with most webcam images containing some amount of distortion*

The first thing to check is that left and right cameras are connected correctly.  Looking from behind the stereo camera the left camera should be on your left.  You can check this simply by covering the lens of one of the cameras.  If the cameras are in the wrong order exit the program, unplug the cameras and plug them back in the other way around.

5.  If the pattern does not fill the entire image you can define a _region of interest_ by clicking on the top left or bottom right areas of the image.  This will instruct the program where to look for edge features.  Regions of interest appear as green boxes.

6.  Click on the button marked *Calibration* to begin the calibration process.

7.  A status message to the left of the screen will show when the automatic calibration is completed.  If the calibration seems to be taking a long time use the drop down list to select edges, corners or lines and check that these features are being detected properly.  Using the drop down list check the rectified images to see that they look reasonable.  A common problem is that the centre spot indicated by a white square within the corners image is not being detected, which may be due to bad lighting.  If the calibration has been successfully completed the view will automatically switch to show the rectified image.  Just for fun, an example of a *bad rectification* is shown below.

[http://sentience.googlegroups.com/web/calibration_bad.jpg]

8.  When you are happy that all is well, select *Save As* from the *File* menu to save the calibration results.  Parameters for stereo camera calibration are stored within an XML format which may then be read by other programs within the _Sentience_ system.  A typical calibration file looks like this:

{{{

<?xml version="1.0" encoding="ISO-8859-1"?>
<!--Sentience 3D Perception System-->
<Sentience>
  <StereoCamera>
    <!--Name of the WDM software driver for the cameras-->
    <DriverName>Creative WebCam NX Ultra</DriverName>
    <!--Position and orientation of the camera relative to the robots head or body-->
    <PositionOrientation>
      <!--Position in millimetres-->
      <PositionMillimetres>0,0,0</PositionMillimetres>
      <!--Orientation in degrees-->
      <OrientationDegrees>0,0,0</OrientationDegrees>
    </PositionOrientation>
    <!--Focal length in millimetres-->
    <FocalLengthMillimetres>5</FocalLengthMillimetres>
    <!--Camera baseline distance in millimetres-->
    <BaselineMillimetres>100</BaselineMillimetres>
    <!--Calibration Data-->
    <Calibration>
      <!--Image offsets in pixels due to small missalignment from parallel-->
      <Offsets>23.21169,-1</Offsets>
      <Camera>
        <!--Horizontal field of view of the camera in degrees-->
        <FieldOfViewDegrees>78</FieldOfViewDegrees>
        <!--Image dimensions in pixels-->
        <ImageDimensions>320,240</ImageDimensions>
        <!--The centre of distortion in pixels-->
        <CentreOfDistortion>157,112</CentreOfDistortion>
        <!--Polynomial coefficients used to describe the camera lens distortion-->
        <DistortionCoefficients>0,1.231268,0.0002229516</DistortionCoefficients>
        <!--Scaling factor-->
        <Scale>0.8125</Scale>
        <!--Rotation of the image in degrees-->
        <RotationDegrees>-0.3941584</RotationDegrees>
        <!--The minimum RMS error between the distortion curve and plotted points-->
        <RMSerror>3.328376</RMSerror>
      </Camera>
      <Camera>
        <!--Horizontal field of view of the camera in degrees-->
        <FieldOfViewDegrees>78</FieldOfViewDegrees>
        <!--Image dimensions in pixels-->
        <ImageDimensions>320,240</ImageDimensions>
        <!--The centre of distortion in pixels-->
        <CentreOfDistortion>155,113</CentreOfDistortion>
        <!--Polynomial coefficients used to describe the camera lens distortion-->
        <DistortionCoefficients>0,1.15394,0.0006436906</DistortionCoefficients>
        <!--Scaling factor-->
        <Scale>0.8125</Scale>
        <!--Rotation of the image in degrees-->
        <RotationDegrees>-0.6620849</RotationDegrees>
        <!--The minimum RMS error between the distortion curve and plotted points-->
        <RMSerror>3.4475</RMSerror>
      </Camera>
    </Calibration>
  </StereoCamera>
</Sentience>

}}}


=== What to do next? ===

[RobotDesigner Design your robot]

=== Further Reading ===

For more information on camera calibration methods a nice summary of the history of this subject can be found in [http://sluggish.uni.cc/sentience/CameraCalibrationMethods.pdf The Development of Camera Calibration Methods and Models] by T.A. Clarke and J.G. Fryer.

Also see [http://www.dis.uniroma1.it/~iocchi/stereo/calib.html Calibration of Stereo Cameras for Mobile Robots] by [http://www.dis.uniroma1.it/~iocchi/ Luca Iocchi].



