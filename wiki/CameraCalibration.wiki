#summary Calibrating methods for stereo cameras
#labels calibration,cameralens

Camera images normally contain some amount of spherical distortion, sometimes known as the _goldfish bowl effect_.  Linear features such as chair legs or door frames may appear to be warped, especially at the periphery of the image.  The job of camera calibration is to discover the nature of this distortion so that the resulting image may subsequently be undistorted or [ImageRectification rectified].

Various methods of calibration exist.  The simplest method assumes a perfectly symmetrical lens around the [CentreOfDistortion centre of distortion], and uses a polynomial equation to represent how light rays are bent radially around this by the curvature of the lens.

The typical method of calibration involves having the camera observe a test pattern, which can consist of spots, lines or squares (or indeed any easily identifiable repeating pattern).  Since the real geometry of the pattern is known the lens distortion can be calculated, then used to rectify the image back into a flat geometry.

=== Stages of Calibration ===

The images below show the stages involved in the calibration process.

[http://sluggish.uni.cc/sentience/calibration_steps.jpg]

1.  *Edge detection*  Edges are detected within the entire image, or within some _region of interest_ which contains the calibration pattern.  Edges are local points of high contrast, and a competitive _non-maximal supression_ is used to show only the strongest features.  In order to make edge detection more robust multiple images taken over a period of time are integrated together.  This helps to average out much of the noise normally present within webcam images.

2.  *Line detection*  Once edges have been detected horizontally and vertically oriented lines can be fitted to them.  Some extra local fitting is done to ensure that the lines closely match those within the original image.

3.  *Corner detection*  When lines have been found the intersections between lines may be used to discover corner features.

4.  *Centre spot detection*  We also need to know the centre position of the calibration pattern, because this is at a known distance from the camera.  The centre of the pattern is indicated by a small spot, which is offset north west, north east, south west or south east from the centre of pattern.  The centre spot is easily located by searching for the maximal _off-centre_ response within the image which has not been previously identified as a corner feature.  The corner feature which corresponds to the centre of the pattern is marked with a small white square.

5.  *Forward feature projection*  Knowning the position of the centre of the calibration pattern, its distance from the camera, the height of the camera above the ground, field of vision and the spacing of the pattern we can then calculate where corner features _ought to appear_ within the image if it were perfectly rectified.  This is a kind of top-down expectation projected into image coordinates.

6.  *Polynomial curve fit*  We can plot the radial positions (distance from the centre of the image) for the observed corners and the forward projected corners on a 2D graph and use classical polynomial curve fitting in order to discover the shape of the image distortion caused by the camera lens.  The fitting procedure may be carried out using an origin within some small radius of the centre of the image, and the solution with the smallest _root mean squared_ error then gives us a position for the _centre of the distortion_.

[http://sluggish.uni.cc/sentience/calibration_polynomial.jpg]

7.  *Shake and bake*  Once a good curve fit has been discovered a small amount of random noise is added and a secondary function is used to evaluate the quality of fit to the image, by comparing the rectified corner feature positions to the forward projected corners.  This allows the curve to be fine tuned to get the closest possible match.

8.  *Rectification*  The centre of distorion and polynomial curve may be used to rectify images from the camera.


The assumption that the lens distortion is radially symmetric is of course not always true, especially on low cost webcams where the quality of manufacture may not be especially high.

=== Users guide ===

_Sentience_ contains an automatic monocular or stereo camera calibration system, which requires a calibration pattern.  I have tried to keep this procedure as simple as possible, so that it can be carried out _in the field_ by a non-expert using only easily available materials.

Ingredients required:

  *  Large piece of cardboard
  *  Black marker pen
  *  Tape measure
  *  Straight object to use as a drawing guide, such as a ruler or piece of wood

Instructions:

1.  Draw a grid pattern on the cardboard using the pen and some straight object as a guide.  Cardboard is a good material to use, since it is non-reflective and easy to draw on.  You can choose anything you like as the spacing between lines (provided that it's regular).  I've found that 50 millimetres (5cm) seems to be a good spacing value.

2.  Lay the calibration pattern down on the floor and have the stereo camera look down towards the centre of the pattern.  Ensure that the centre of the two cameras is aligned with the centre of the pattern.  The cameras would typically be mounted on a pan and tilt mechanism on the head of a robot, but in this case I'm just using the back of a chair as a substitute for a mobile robot.

[http://sluggish.uni.cc/sentience/calibration_pattern.jpg]

3.  Measure the distance along the ground from the stereo camera to the centre of the calibration pattern.  Also, measure the height of the cameras above the floor.  To be as accurate as possible you should be measuring distances from the lenses of the cameras.

4.  Run the calibration program and enter the measurement values, pattern spacing, field of vision and stereo camera baseline distance, then from *video* on the menu bar select *start camera*.  When the cameras are running use the large white crosshairs to align the cameras with the pattern, like this:

[http://sluggish.uni.cc/sentience/calibration_roi.jpg]

5.  If the pattern does not fill the entire image you can define a _region of interest_ by clicking on the top left or bottom right areas of the image.  This will instruct the program where to look for edge features.

6.  From *Tools* on the menu bar select *Reset calibration data*.  This will reset all previous calculations which might have occured whilst you were physically setting up/aligning the system and begin calibrating.

7.  A status message to the left of the screen will show when the automatic calibration is completed.  If the calibration seems to be taking a long time use the drop down list to select edges, corners or lines and check that these features are being detected properly.

8.  Using the drop down list check the rectified images to see that they look reasonable.  Just for fun, an example of a *bad rectification* is shown below.

[http://sluggish.uni.cc/sentience/calibration_roi.jpg]


=== Further Reading ===

For more information on camera calibration methods a nice summary of the history of this subject can be found in [http://sluggish.uni.cc/sentience/CameraCalibrationMethods.pdf The Development of Camera Calibration Methods and Models] by T.A. Clarke and J.G. Fryer.
