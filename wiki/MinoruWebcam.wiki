#summary The first commercial stereoscopic webcam
#labels webcam,minoru,stereocamera,stereovision,stereoscopic,stereocorrespondence,elas

[http://lh6.ggpht.com/_cGREIsCvj4M/S6zMBC7BevI/AAAAAAAAAjU/YZNB1Uu1Zzo/Minoru.jpg]

= Introduction =

The Minoru is the first commercially available stereo webcam.  It's primarily intended for entertainment - broadcasting stereo anaglyphs as a novel alternative to the usual webcam based video conferencing or blogging.  However, it also makes a good inexpensive range sensor for robotics use.

= Disassembly =

The Minoru comes in a casing which is attractive, but not very easy to mount onto a flat surface.  The outer casing can be removed as follows:

  # Remove the camera stand using a hacksaw just beneath the main body of the camera.
  # The silver band around the centre of the camera can then be removed in two sections.
  # Using a knife or precision screwdriver carefully separate the two halves of the casing.  This can be quite tricky.
  # Remove the white plastic lens covers and any surrounding foam.
  # You may wish to remove the rubber backing, or keep it in place to insulate the electronics from the surface upon which you're mounting the camera.
  # Finally you should have extracted the camera board, which looks like the picture above.

= Software = 

The Minoru is UVC compilant, and therefore very easy to use on a GNU/Linux operating system.  Plug in the camera, then open a command shell and type:

{{{
ls /dev/video*
}}}

This should display two extra video devices.  If you are using a kernel with a version earlier than 2.6.30, obtain the latest UVC driver from [http://linuxtv.org/hg/~pinchartl/uvcvideo here] then install it (possibly you might need to reboot for the new driver to take effect).

You can test out the webcam using a program called *v4l2stereo*, which is part of a project called [http://code.google.com/p/libv4l2cam/ libv4l2cam] which is related to the Sentience project, and is also under the General Public License.  A [http://code.google.com/p/libv4l2cam/ deb package] is available for easy installation on Debian based distros.  Versions 1.043 and above use the OpenCV version 2 packages which are part of Ubuntu 10.04 (or later).  You will need to install [http://code.google.com/p/libv4l2cam/downloads/detail?name=libcvm57.deb libcvm57] (or later) before installing the v4l2stereo package.

_v4l2stereo_ can be used in various ways, but to check that the Minoru is working you can use the following command.

{{{
v4l2stereo -0 /dev/video1 -1 /dev/video0 --features
}}}

This assumes that the left camera is video device number 1 and the right camera is video device number 0, and should display two images showing the edge features which are the basis for stereo matching, like this:

[http://lh4.ggpht.com/_cGREIsCvj4M/S6zMA5dcFBI/AAAAAAAAAjQ/_yodyK0qInw/edge_features.jpg]

So, once you have established that the cameras are working the first thing to do is calibrate them using the _--calibrate_ option.  This uses the OpenCV stereo camera calibration routines in order to obtain the optical parameters.  First, print out a [http://code.google.com/p/libv4l2cam/downloads/detail?name=chess9x6_25mm.pdf calibration pattern], which consists of a checkerboard pattern, and mount it on a rigid backing such as cardboard or wood.  Then type:

{{{
v4l2stereo --dev0 /dev/video1 --dev1 /dev/video0 --calibrate "6 9 24"
}}}

The first number of the calibrate option is the number of squares across, the second is the number of squares down, and the third is the size of each square in millimetres.  The order of the dimensions should correspond to how the calibration pattern is presented to the cameras.  The video below shows the procedure.

<wiki:video url="http://www.youtube.com/watch?v=o9aUhDe_vPQ"/>


Once camera calibration is complete the parameters are automatically saved to a file called _calibration.txt_.  Normally when running _v4l2stereo_ the program will search for this file in the current directory, but optionally you can also specify it as follows:

{{{
v4l2stereo -0 /dev/video1 -1 /dev/video0 --calibrationfile calibration.txt
}}}

To test the image rectification:

{{{
v4l2stereo -0 /dev/video1 -1 /dev/video0
}}}

If the rectification is good you should notice that when the left and right images are placed side by side the rows of both images correspond.  If there is any vertical displacement it is possible to manually alter this, either by editing the _vshift_ parameter within _calibration.txt_ or by using the _--offsety_ option.

You can then test stereo correspondence like this:

{{{
v4l2stereo -0 /dev/video1 -1 /dev/video0 --disparitymap
}}}

This currently uses the [http://www.rainsoft.de/software/libelas.html ELAS] algorithm for dense stereo.  [http://en.wikipedia.org/wiki/Histogram_equalization Histogram equalization] is also useful to help improve stereo correspondence results.

{{{
v4l2stereo -0 /dev/video1 -1 /dev/video0 --disparitymap --equal
}}}

<wiki:video url="http://www.youtube.com/watch?v=blynlw1YUKs"/>

A threshold can also be applied, so that only nearby objects are visible.  This can be useful for detecting people at close range.

{{{
v4l2stereo -0 /dev/video1 -1 /dev/video0 --disparitymap --equal --disparitythreshold 15
}}}

Using the disparity threshold it's also possible to substitute a background image.

{{{
v4l2stereo -0 /dev/video1 -1 /dev/video0 --background mybackground.jpg --equal --disparitythreshold 7
}}}

The above uses a global disparity threshold, but if your stereo camera is always fixed in place (for example, a fixed security camera) then it's also possible to create a _background model_, which in effect is like having an individual disparity threshold for each pixel.  If you're trying to detect people, make sure that there is nobody in view when making the model.  To create a background model file:

{{{
v4l2stereo -0 /dev/video1 -1 /dev/video0 --learnbackground model.dat --equal
}}}

Then to subsequently use the model:

{{{
v4l2stereo -0 /dev/video1 -1 /dev/video0 --disparitymap --equal --backgroundmodel model.dat --disparitythreshold 3
}}}

This means that only pixels having a disparity of three or greater relative to the background will be shown.  Similar to the global disparity threshold situation you can also use a background image if you wish.

{{{
v4l2stereo -0 /dev/video1 -1 /dev/video0 --background mybackground.jpg --equal --backgroundmodel model.dat --disparitythreshold 3
}}}

The effective stereo range of the Minoru, using 320x240 images, is between 35cm and 2 metres.  The range is limited mainly by the baseline distance between the cameras and the image resolution.  For close up tasks such as manipulation or inspection of objects this might be quite a useful off-the-shelf sensor.

A greater effective range of approximately 3-4 metres can be obtained by using a higher resolution.  However, this requires a slower frame rate, and differences in frame capture times due to unsynchronized capture become a far greater issue.  Also you will need to recalibrate using the higher resolution.  Note that camera calibration at 640x480 resolution can be somewhat haphazard, and may take several attempts before a good rectification result is obtained.

{{{
v4l2stereo -0 /dev/video1 -1 /dev/video0 -w 640 -h 480 --fps 15 --disparitymap --equal
}}}


= Network streaming and headless operation =

It's possible to stream video over a network using [http://gstreamer.freedesktop.org/ gstreamer].  This can be useful for remotely operated vehicles or surveillance systems.

On the server:

{{{
v4l2stereo -0 /dev/video1 -1 /dev/video0 --disparitymap --equal --stream --headless
}}}

then on the client:

{{{
gst-launch tcpclientsrc host=[ip] port=5000 ! multipartdemux ! jpegdec ! autovideosink
}}}

To do a local test you can use _localhost_ as the IP address.

= Development =

*Required OpenCV packages*

If you wish to do development on the v4l2stereo code you will need to ensure that opencv packages are installed.  On Ubuntu 10.04 or later this is easily achieved as follows:

{{{
    sudo apt-get install libcv2.1 libhighgui2.1 libcvaux2.1 libcv-dev libcvaux-dev libhighgui-dev libgstreamer-plugins-base0.10-dev libgst-dev
}}}

*Configuring for use with Eclipse*

To use with the Eclipse C++ IDE:

 *  Create a new C++ project

 *  Import the source from the _Import/File System option_

 *  Within the project properties select _C++ Build/Settings_

 *  Under _GCC C++ Compiler/Directories/Include paths (-l)_ enter

{{{
/usr/include/opencv
/usr/include/gstreamer-0.10
}}}

 *  Under _GCC C++ Compiler/Miscellaneous_ enter

{{{
-c -fopenmp -fmessage-length=0 -lcam -lcv -lcxcore -lcvaux -lhighgui `pkg-config --cflags --libs gstreamer-0.10` -L/usr/lib -lcv -lcxcore -lcvaux -lhighgui `pkg-config --cflags --libs glib-2.0` `pkg-config --cflags --libs gstreamer-plugins-base-0.10` -lgstapp-0.10
}}}

 *  Under _GCC C++ Linker/Libraries/Libraries (-l)_ enter

{{{
cv
cxcore
gstapp-0.10
highgui
}}}

 *  Under _GCC C++ Linker/Libraries/Library search path (-L)_ enter

{{{
/usr/lib
/usr/lib/gstreamer-0.10
}}}

 *  Under _GCC C++ Linker/Miscellaneous/Linker flags_ enter

{{{
/usr/lib/libcxcore.so /usr/lib/libcvaux.so /usr/lib/libcv.so /usr/lib/libhighgui.so
}}}

After applying those settings you should now be able to compile the project within Eclipse.

= Integration with ROS =

The [http://code.google.com/p/libv4l2cam/ source package] also contains an example of integrating v4l2stereo with [http://www.ros.org ROS] - the robot operating system produced by [http://www.willowgarage.com/ Willow Garage].  This would make it possible to replace more expensive stereo cameras with something like a Minoru.  The only real advantage that the more expensive stereo cameras have is synchronized frame capture, which is advantageous when the robot is in motion.

*Making the package*

Add the following line to the end of ~/.bashrc

{{{
source ~/develop/libv4l2cam/ros/setup.sh
}}}

pointing to the directory where the stereocam ROS package is located.  Check that the paths within setup.sh are appropriate for your ROS installation.

Reload

{{{
. ~/.bashrc
}}}

Then make the package as follows:

{{{
rosmake --rosdep-install stereocam
}}}

*Running the ROS publisher (broadcasting service)*

Start ROS:

{{{
roscore
}}}

Then in a separate shell begin broadcasting:

{{{
rosrun stereocam stereocam_broadcast _index:=0
}}}

Where _index_ is an index number assigned to the stereo camera, since it's possible that multiple stereo cameras could be attached.  In another shell you can subscribe to the broadcast:

{{{
rosrun stereocam stereocam_subscribe
}}}

To check that the images are being published:

{{{
rostopic list
}}}

should show /stereo/left/image_raw0 and /stereo/right/image_raw0, and also compressed versions of these if image_transport has been enabled.

To enable compressed image transport, for efficient transport of images over networks:

{{{
rosparam set /compressed_listener/image_transport compressed
}}}

then restart the broadcast and subscriber.

A disparity map of the type [http://www.ros.org/doc/api/sensor_msgs/html/msg/Image.html sensor_msgs::Image] (one byte per pixel) is also published.  This was used instead of [http://www.ros.org/wiki/stereo_msgs stereo_msgs::DisparityImage] because it provides the ability to transport disparity maps efficiently over networks using image_transport.  The disparity value is remapped into a 0-255 range.

_stereocam_subscribe.cpp_ is only intended to be illustrative of how to connect to the stereo camera using ROS and receive a disparity map.  You can use this as a guideline to how to integrate with your own system.

= Other things to try =

One limitation of the Minoru is that the field of view is quite narrow - only about 40 degrees - giving it a tunnel vision which is fairly standard for webcams.  For robotics use a wider field of view would be preferable, and it may be possible to replace the lenses (M12 fittings which screw in).  _v4l2stereo_ includes options which allow you to rectify the images if the camera calibration parameters are known.

After searching around and trying a few different lens types I found that the following specification works well.

{{{
Angle of view: 180 degrees
Focal length: 1.8mm
Back focal length: 5.44mm
Format: 1/3", 1/4"
Aperture: F2.0
}}}

The most important figure here is the _back focal length_, which is the distance between the back of the lens and the CCD or CMOS sensor.  If this is longer than about 7mm then the lens will usually not fit into the short lens mountings on the Minoru, which are only about 10mm in height above the circuit board.  In this case the field of view is actually less than the full 180 degrees, because the sensor size is smaller than the quoted format sizes.

With wide angle lenses fitted, the Minoru looks like this:

[http://groups.google.com/group/sentience/web/minoru_wide_angle2.jpg]